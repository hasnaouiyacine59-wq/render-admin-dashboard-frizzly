# Incremental Sync Implementation

## Overview

Implemented a **persistent local cache with incremental sync** that:
1. Loads all orders once (first time)
2. Stores them locally in JSON files
3. Only fetches NEW orders on subsequent requests
4. Dramatically reduces Firestore reads

---

## How It Works

### First Load (Cold Start)
```
Admin visits /orders
  â†“
Check local cache â†’ Empty
  â†“
Fetch ALL orders from Firestore (1000 reads)
  â†“
Save to local file: cache_data/orders.json
  â†“
Save last timestamp: cache_data/orders_meta.json
  â†“
Display orders
```

### Subsequent Loads (Incremental Sync)
```
Admin visits /orders
  â†“
Check local cache â†’ Found (1000 orders)
  â†“
Get last sync timestamp: 1709064000000
  â†“
Query Firestore: WHERE timestamp > 1709064000000
  â†“
Found 5 new orders (5 reads only!)
  â†“
Merge with cached orders (1000 + 5 = 1005)
  â†“
Update local cache
  â†“
Display orders
```

---

## Files Created

### 1. **persistent_cache.py**
Manages local JSON file storage:
- `cache_data/orders.json` - Stores all orders
- `cache_data/orders_meta.json` - Stores last sync timestamp

### 2. **sync_service.py**
Handles incremental sync logic:
- `sync_orders()` - Syncs orders incrementally
- `sync_products()` - Syncs products incrementally
- `force_refresh()` - Forces full reload

### 3. **blueprints/orders.py** (MODIFIED)
Now uses incremental sync instead of direct Firestore queries

---

## Performance Impact

### Before (Direct Firestore Query)
```
Visit /orders â†’ 50 reads (page 1)
Visit /orders?page=2 â†’ 50 reads (page 2)
Visit /orders?page=3 â†’ 50 reads (page 3)
Total: 150 reads
```

### After (Incremental Sync)
```
First visit /orders â†’ 1000 reads (load all) â†’ Save to cache
Second visit /orders â†’ 5 reads (only new orders)
Third visit /orders â†’ 2 reads (only new orders)
Fourth visit /orders â†’ 0 reads (no new orders)
Total: 1007 reads

But now you have ALL orders locally!
- Pagination: 0 reads (from cache)
- Filtering: 0 reads (from cache)
- Sorting: 0 reads (from cache)
```

---

## Cost Comparison

### Scenario: 100 admin sessions/day, 10 page views per session

**Before (Direct Query):**
- 100 sessions Ã— 10 pages Ã— 50 reads = 50,000 reads/day
- 1,500,000 reads/month = **$0.90/month**

**After (Incremental Sync):**
- Day 1: 100 sessions Ã— 1000 reads (first load) = 100,000 reads
- Day 2-30: 100 sessions Ã— 10 new orders = 1,000 reads/day
- Total: 100,000 + (29 Ã— 1,000) = 129,000 reads/month = **$0.08/month**

**Savings: $0.82/month (91% reduction)**

---

## Usage

### Automatic Sync
Just visit the orders page - sync happens automatically:
```
http://localhost:5000/orders
```

### Force Refresh
To reload all orders from Firestore:
```
http://localhost:5000/orders?refresh=1
```

### Manual Sync API
Trigger sync programmatically:
```bash
curl -X POST http://localhost:5000/api/sync-orders
```

Response:
```json
{
  "success": true,
  "total_orders": 1005,
  "message": "Orders synced successfully"
}
```

---

## Cache Files

### Location
```
cache_data/
â”œâ”€â”€ orders.json          # All orders data
â”œâ”€â”€ orders_meta.json     # Last sync timestamp
â”œâ”€â”€ products.json        # All products data
â””â”€â”€ products_meta.json   # Last sync timestamp
```

### orders.json Structure
```json
{
  "order_id_1": {
    "id": "order_id_1",
    "orderId": "ORD-001",
    "status": "PENDING",
    "totalAmount": 150.00,
    "timestamp": 1709064000000,
    ...
  },
  "order_id_2": { ... }
}
```

### orders_meta.json Structure
```json
{
  "last_sync_timestamp": 1709064000000,
  "last_sync_date": "2026-02-27T20:00:00"
}
```

---

## Cache Invalidation

### Automatic Invalidation
Cache is automatically refreshed when:
- Order status is updated
- Bulk update is performed
- Force refresh is triggered

### Manual Invalidation
```python
from sync_service import sync_service

# Force refresh orders
sync_service.force_refresh('orders')

# Force refresh products
sync_service.force_refresh('products')
```

---

## Monitoring

### Check Sync Logs
```bash
tail -f app.log | grep SYNC
```

Output:
```
[SYNC] First sync - loading all orders (limited to 1000)
[SYNC] Cached 1000 orders, latest timestamp: 1709064000000
[SYNC] Incremental sync from timestamp: 1709064000000
[SYNC] Found 5 new/updated orders
```

### Check Cache Files
```bash
# View cached orders count
cat cache_data/orders.json | jq 'length'

# View last sync time
cat cache_data/orders_meta.json | jq '.last_sync_date'
```

---

## Advanced Features

### 1. Background Sync (Optional)

Add automatic background sync every 5 minutes:

```python
# In app.py
from threading import Thread
import time

def background_sync():
    while True:
        time.sleep(300)  # 5 minutes
        try:
            sync_service.sync_orders()
            app.logger.info("[BACKGROUND] Orders synced")
        except Exception as e:
            app.logger.error(f"[BACKGROUND] Sync error: {e}")

# Start background thread
if __name__ == '__main__':
    sync_thread = Thread(target=background_sync, daemon=True)
    sync_thread.start()
    app.run(host='0.0.0.0', port=5000)
```

### 2. Real-time Sync with Firestore Listeners

For true real-time updates:

```python
# In sync_service.py
def start_realtime_sync():
    """Listen to Firestore changes in real-time"""
    def on_snapshot(col_snapshot, changes, read_time):
        for change in changes:
            if change.type.name in ['ADDED', 'MODIFIED']:
                doc = change.document
                data = doc.to_dict()
                data['id'] = doc.id
                
                # Update cache
                cached_orders = persistent_cache.get_collection('orders')
                cached_orders[doc.id] = data
                persistent_cache.save_collection('orders', cached_orders, data.get('timestamp', 0))
                
                print(f"[REALTIME] Order {doc.id} updated in cache")
    
    # Start listener
    db.collection('orders').on_snapshot(on_snapshot)
```

### 3. Compression (For Large Datasets)

If cache files get too large:

```python
import gzip
import json

def save_compressed(file_path, data):
    with gzip.open(f"{file_path}.gz", 'wt', encoding='utf-8') as f:
        json.dump(data, f)

def load_compressed(file_path):
    with gzip.open(f"{file_path}.gz", 'rt', encoding='utf-8') as f:
        return json.load(f)
```

---

## Troubleshooting

### Cache Not Updating
```bash
# Clear cache and force refresh
rm -rf cache_data/
# Then visit /orders?refresh=1
```

### Too Many Orders in Cache
```python
# Limit initial load in sync_service.py
orders_query = db.collection('orders').order_by('timestamp', direction=firestore.Query.DESCENDING).limit(500)  # Reduce from 1000
```

### Timestamp Issues
Ensure all orders have a `timestamp` field:
```python
# When creating orders in your app
order_data = {
    'orderId': 'ORD-001',
    'timestamp': int(time.time() * 1000),  # Current timestamp in milliseconds
    ...
}
```

---

## Migration from Old System

### Step 1: Deploy New Code
```bash
git pull
python app.py
```

### Step 2: First Load
Visit `/orders` - this will create the initial cache (1000 reads)

### Step 3: Verify Cache
```bash
ls -lh cache_data/
# Should see orders.json and orders_meta.json
```

### Step 4: Test Incremental Sync
1. Create a new order in your app
2. Visit `/orders` again
3. Check logs: should see "Found 1 new/updated orders"

---

## Best Practices

### 1. Regular Cache Refresh
Set up a daily cache refresh:
```bash
# Add to crontab
0 3 * * * curl -X POST http://localhost:5000/api/sync-orders
```

### 2. Backup Cache Files
```bash
# Backup cache daily
cp -r cache_data/ cache_data_backup_$(date +%Y%m%d)/
```

### 3. Monitor Cache Size
```bash
# Check cache size
du -sh cache_data/
```

### 4. Set Cache Limits
Modify `sync_service.py` to limit cache size:
```python
# Keep only last 30 days of orders
thirty_days_ago = int((datetime.now() - timedelta(days=30)).timestamp() * 1000)
orders_query = db.collection('orders').where('timestamp', '>', thirty_days_ago)
```

---

## Summary

âœ… **Implemented:**
- Persistent local cache (JSON files)
- Incremental sync (only fetch new orders)
- Automatic cache updates
- Force refresh capability
- Manual sync API

âœ… **Benefits:**
- 91% reduction in Firestore reads
- Instant pagination (0 reads)
- Instant filtering (0 reads)
- Works offline (uses cached data)
- Scales to thousands of orders

âœ… **Trade-offs:**
- First load takes longer (1000 reads)
- Requires disk space for cache
- Slight delay for new orders (until next sync)

---

## Next Steps

1. âœ… Test the implementation
2. âœ… Monitor sync logs
3. âœ… Add background sync (optional)
4. âœ… Implement for products/users
5. âœ… Set up cache backup

**Your dashboard now has intelligent incremental sync!** ðŸš€
